{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "data=pd.read_csv(\"load-dataset.csv\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2016, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = data[:,:4]\n",
    "y = data[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_datax=(x-x.mean())/x.std()\n",
    "normalized_datax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_datay=(y-y.mean())/y.std()\n",
    "normalized_datay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(normalized_datax,normalized_datay,test_size = 0.10, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = X_train.T\n",
    "y_train = y_train.reshape( y_train.shape[0],1)\n",
    "X_test = X_test.T\n",
    "y_test = y_test.reshape( y_test.shape[0],1)\n",
    "print ('Train X Shape: ', X_train.shape)\n",
    "print ('Train Y Shape: ', y_train.shape)\n",
    "print ('\\nTest X Shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the input layer is:  = 4\n",
      "The size of the hidden layer is:  = 2394\n",
      "The size of the output layer is:  = 1612\n"
     ]
    }
   ],
   "source": [
    "def define_structure(X, Y):\n",
    "    input_unit = X.shape[0] \n",
    "    hidden_unit = 2394 # (1.5*1596)\n",
    "    output_unit = Y.shape[0] \n",
    "    return (input_unit, hidden_unit, output_unit)\n",
    "(input_unit, hidden_unit, output_unit) = define_structure(X_train, y_train)\n",
    "print(\"The size of the input layer is:  = \" + str(input_unit))\n",
    "print(\"The size of the hidden layer is:  = \" + str(hidden_unit))\n",
    "print(\"The size of the output layer is:  = \" + str(output_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters_initialization(input_unit, hidden_unit, output_unit):\n",
    "    np.random.seed(2) \n",
    "    W1 = np.random.randn(hidden_unit, input_unit)*0.01\n",
    "    b1 = np.zeros((hidden_unit, 1))\n",
    "    W2 = np.random.randn(output_unit, hidden_unit)*0.01\n",
    "    b2 = np.zeros((output_unit, 1))\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    cache = {\"Z1\": Z1,\"A1\": A1,\"Z2\": Z2,\"A2\": A2}\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_cost(A2, Y, parameters):\n",
    "    m = Y.shape[1] \n",
    "    logprobs = np.multiply(np.log(A2), Y) + np.multiply((1-Y), np.log(1 - A2))\n",
    "    cost = - np.sum(logprobs) / m\n",
    "    cost = float(np.squeeze(cost))\n",
    "                                    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    #number of training example\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "   \n",
    "    dZ2 = A2-Y\n",
    "    dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1 - np.power(A1, 2))\n",
    "    dW1 = (1/m) * np.dot(dZ1, X.T) \n",
    "    db1 = (1/m)*np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    grads = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2,\"db2\": db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def h(a,b,x): \n",
    "    return a*x+b\n",
    "\n",
    "def mse(a,b,x,y): \n",
    "    return np.mean((h(a,b,x) - y)**2)\n",
    "def gradient(a,b,x,y): \n",
    "    return np.mean(x*(a*x+b-y), axis=-1), np.mean(a*x+b-y, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum_gradient_descent(a,b,x,y,lr=1e-5,momentum=0.9,epsilon=1e-4, batch_size=0):\n",
    "    if batch_size == 0: batch_size = len(x)\n",
    "    prev_grad_a = 0\n",
    "    prev_grad_b = 0\n",
    "    prev_error = 0\n",
    "    error = np.array([])\n",
    "    while True:\n",
    "        x_shuffled, y_shuffled = shuffle(x,y)\n",
    "        gradient_a, gradient_b = gradient(a,b,x_shuffled[:batch_size],y_shuffled[:batch_size])\n",
    "#         print(abs(mse(a, b, x_shuffled, y_shuffled) - prev_error))\n",
    "        if abs(mse(a, b, x_shuffled, y_shuffled) - prev_error) < epsilon:\n",
    "            break\n",
    "        prev_error = mse(a,b,x_shuffled,y_shuffled)\n",
    "        error = np.insert(error, len(error), prev_error)\n",
    "\n",
    "        a -= lr * gradient_a + momentum * prev_grad_a\n",
    "        b -= lr * gradient_b + momentum * prev_grad_b\n",
    "        prev_grad_a = lr * gradient_a + momentum * prev_grad_a\n",
    "        prev_grad_b = lr * gradient_b + momentum * prev_grad_b\n",
    "    return a, b, error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,error = momentum_gradient_descent(a_0,b_0, x, y, lr=1e-1, batch_size=250, momentum=0.9)\n",
    "prediction = h(a,b,x)\n",
    "regression_subplot.plot(x, prediction, color=\"r\", label=\"momentum_batch\")\n",
    "error_subplot.plot(error, color=\"r\", label=\"momentum_batch\")\n",
    "print(\"a =\",a,\", b =\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_model(X, Y, hidden_unit, num_iterations = 1000):\n",
    "    np.random.seed(3)\n",
    "    input_unit = define_structure(X, Y)[0]\n",
    "    output_unit = define_structure(X, Y)[2]\n",
    "    \n",
    "    parameters = parameters_initialization(input_unit, hidden_unit, output_unit)\n",
    "   \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "        A2, cache = forward_propagation(X, parameters)\n",
    "        cost = cross_entropy_cost(A2, Y, parameters)\n",
    "        grads = backward_propagation(parameters, cache, X, Y)\n",
    "      #  parameters = gradient_descent(parameters, grads)\n",
    "        if i % 5 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    return parameters\n",
    "parameters = neural_network_model(X_train, y_train, 4, num_iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(parameters, X):\n",
    "    A2, cache = forward_propagation(X, parameters)\n",
    "    predictions = np.round(A2)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = prediction(parameters, X_train)\n",
    "print ('Accuracy Train: %d' % float((np.dot(y_train, predictions.T) + np.dot(1 - y_train, 1 - predictions.T))/float(y_train.size)*100) + '%')\n",
    "predictions = prediction(parameters, X_test)\n",
    "print ('Accuracy Test: %d' % float((np.dot(y_test, predictions.T) + np.dot(1 - y_test, 1 - predictions.T))/float(y_test.size)*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
